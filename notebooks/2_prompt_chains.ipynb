{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49dc45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a5170a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2658a523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform is a higher-order function in PySpark for arrays. It applies a function to each element of an array column and returns an array of the results.\n",
      "\n",
      "Key points\n",
      "- Works on array columns (not maps). For maps, use transform_values or transform_keys.\n",
      "- The lambda receives each element as a column expression and should return a column expression.\n",
      "- Useful to avoid Python UDFs and stay within Spark’s optimized engine.\n",
      "\n",
      "Basic usage\n",
      "- Example data and import:\n",
      "  from pyspark.sql import functions as F\n",
      "  df = spark.createDataFrame(\n",
      "      [(1, [1, 2, 3]), (2, [4, 5])],\n",
      "      [\"id\", \"nums\"]\n",
      "  )\n",
      "\n",
      "- Double each element in an array:\n",
      "  df2 = df.select(F.transform(\"nums\", lambda x: x * 2).alias(\"doubled\"))\n",
      "  df2.show()\n",
      "\n",
      "- Use a conditional inside the transform:\n",
      "  df3 = df.select(F.transform(\"nums\", lambda x: F.when(x > 2, x).otherwise(-1)).alias(\"cond\"))\n",
      "  df3.show()\n",
      "\n",
      "- Using a SQL expression (alternative syntax):\n",
      "  df4 = df.selectExpr(\"transform(nums, x -> x * 2) as doubled\")\n",
      "  df4.show()\n",
      "\n",
      "Notes\n",
      "- The lambda can reference other Spark functions, e.g., for more complex logic:\n",
      "  df = df.select(F.transform(\"nums\", lambda x: F.sqrt(x) if x >= 0 else None).alias(\"sqrt_nums\"))\n",
      "  # If you want to combine Spark expressions inside, you can return a Column from the lambda.\n",
      "\n",
      "- Null handling: If the input array or any element is null, the behavior follows Spark’s null semantics (nulls propagate unless explicitly handled).\n",
      "\n",
      "If you share a sample of your data (array column type and desired result), I can provide a tailored example.\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a Databricks developer\"},\n",
    "    {\"role\": \"user\", \"content\": \"Transform function in pyspark.\"}\n",
    "]\n",
    "\n",
    "response = llm.invoke(prompts)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c30177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Transform is a higher-order function in PySpark for arrays. It applies a function to each element of an array column and returns an array of the results.\\n\\nKey points\\n- Works on array columns (not maps). For maps, use transform_values or transform_keys.\\n- The lambda receives each element as a column expression and should return a column expression.\\n- Useful to avoid Python UDFs and stay within Spark’s optimized engine.\\n\\nBasic usage\\n- Example data and import:\\n  from pyspark.sql import functions as F\\n  df = spark.createDataFrame(\\n      [(1, [1, 2, 3]), (2, [4, 5])],\\n      [\"id\", \"nums\"]\\n  )\\n\\n- Double each element in an array:\\n  df2 = df.select(F.transform(\"nums\", lambda x: x * 2).alias(\"doubled\"))\\n  df2.show()\\n\\n- Use a conditional inside the transform:\\n  df3 = df.select(F.transform(\"nums\", lambda x: F.when(x > 2, x).otherwise(-1)).alias(\"cond\"))\\n  df3.show()\\n\\n- Using a SQL expression (alternative syntax):\\n  df4 = df.selectExpr(\"transform(nums, x -> x * 2) as doubled\")\\n  df4.show()\\n\\nNotes\\n- The lambda can reference other Spark functions, e.g., for more complex logic:\\n  df = df.select(F.transform(\"nums\", lambda x: F.sqrt(x) if x >= 0 else None).alias(\"sqrt_nums\"))\\n  # If you want to combine Spark expressions inside, you can return a Column from the lambda.\\n\\n- Null handling: If the input array or any element is null, the behavior follows Spark’s null semantics (nulls propagate unless explicitly handled).\\n\\nIf you share a sample of your data (array column type and desired result), I can provide a tailored example.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 3658, 'prompt_tokens': 23, 'total_tokens': 3681, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 3264, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CyjT6i1aGh7wCO8AfhL2gDEdejBxz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bc835-4f5a-7ae2-a48a-48715269d781-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 23, 'output_tokens': 3658, 'total_tokens': 3681, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 3264}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c1c90",
   "metadata": {},
   "source": [
    "#prompt template, Dynamic promot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7ac45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9714291",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = ChatPromptTemplate.from_messages([\n",
    "    {\"role\": \"system\", \"content\": \"You are a {position}\"},\n",
    "    {\"role\": \"user\", \"content\": \"{query}\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44efe1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['position', 'query'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['position'], input_types={}, partial_variables={}, template='You are a {position}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0d23ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a AI DATA ENGINEER', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Explain role of DATA AI ENGINEER in 1 line.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = prompts.format_messages( position = 'AI DATA ENGINEER',\n",
    "                                       query = 'Explain role of DATA AI ENGINEER in 1 line.' )\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11e3f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.invoke(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddd448c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Data AI Engineer designs and maintains scalable data pipelines and ML systems, integrates data sources, and deploys and monitors AI models to enable data-driven decision making.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba74fd7",
   "metadata": {},
   "source": [
    "# chains runable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed65ef11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a databricks developer', additional_kwargs={}, response_metadata={}), HumanMessage(content='python hi kyu', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts.invoke({\"position\" : \"databricks developer\", \"query\" : \"python hi kyu\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd4f3746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I’m your Python helper. What would you like to do with Python today? Here are a few quick options, or tell me your goal and I’ll tailor it:\n",
      "\n",
      "- Quick hello world: print(\"Hello, world!\")\n",
      "- Learn basics: variables, data types, simple operations\n",
      "- Control flow: if/else, loops\n",
      "- Functions and how to write reusable code\n",
      "- Work on a small problem or bug you have\n",
      "- Help with a project or explain a Python concept\n",
      "\n",
      "If you’re just starting, here are a couple of tiny examples:\n",
      "- Variables and print:\n",
      "  x = 5\n",
      "  y = 2\n",
      "  print(x + y)  # 7\n",
      "- If statement:\n",
      "  if x > 0:\n",
      "      print(\"positive\")\n",
      "- Loop:\n",
      "  for i in range(3):\n",
      "      print(i)\n",
      "- Function:\n",
      "  def greet(name):\n",
      "      return f\"Hello, {name}!\"\n",
      "\n",
      "How would you like to proceed? Tell me your goal, your current level, and the environment you’re using (REPL, script, Jupyter, etc.).\n"
     ]
    }
   ],
   "source": [
    "res = llm.invoke(prompts.invoke({\"position\" : \"Python\", \"query\" : \"python hi kyu\"}))\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a463672",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25659267",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = prompts | llm | out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5575c47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['position', 'query'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['position'], input_types={}, partial_variables={}, template='You are a {position}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 272000, 'max_output_tokens': 128000, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x10f396d50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10fd5a990>, root_client=<openai.OpenAI object at 0x10f395f50>, root_async_client=<openai.AsyncOpenAI object at 0x10fd5a4d0>, model_name='gpt-5-nano', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e83237",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"position\" : \"databricks developer\", \"query\" : \"python hi kyu\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb57ac3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c6f1982",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-series (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
